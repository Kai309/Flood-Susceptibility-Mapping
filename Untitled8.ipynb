{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "22acdd6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topographic Wetness Index: 0.09455337004329506\n",
      "Stream Power Index: 0.024231706710475795\n",
      "Topographic Roughness Index: 0.04746486566989105\n",
      "Topographic Position Index: 0.0034630573735210755\n",
      "Elevation: 0.07057213540553296\n",
      "Land use Land cover: 0.08323217167520407\n",
      "Distance from Road: 0.22493821488487964\n",
      "Distance from River: 0.1401785758864116\n",
      "Slope: 0.024231706710475795\n",
      "Drainage Density: 0.1548220507679782\n",
      "Hillshade: 0.06950745642946633\n",
      "NDVI: 0.03857298173239262\n",
      "Aspect: 0.024231706710475795\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import rasterio\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Define a function to read and resize TIF files\n",
    "def read_and_resize_tif(tif_path, target_shape):\n",
    "    with rasterio.open(tif_path) as src:\n",
    "        data = src.read(\n",
    "            out_shape=(src.count, *target_shape),\n",
    "            resampling=rasterio.enums.Resampling.bilinear\n",
    "        )\n",
    "        return data.flatten(), src.profile\n",
    "\n",
    "# Define paths to your TIF files\n",
    "tif_files = {\n",
    "    \"Topographic Wetness Index\": \"TWI1.tif\",\n",
    "    \"Stream Power Index\": \"SPI1.tif\",\n",
    "    \"Topographic Roughness Index\": \"TRI1.tif\",\n",
    "    \"Topographic Position Index\": \"TPI1.tif\",\n",
    "    \"Elevation\": \"demtif1.tif\",\n",
    "    \"Land use Land cover\": \"lulc1.tif\",\n",
    "    \"Distance from Road\": \"EucDist_road11.tif\",\n",
    "    \"Distance from River\": \"EucDist_Hydr11.tif\",\n",
    "    \"Slope\": \"SLOPEARCGHIS1.tif\",\n",
    "    \"Drainage Density\": \"DRAINAGE DENSITY1.tif\",\n",
    "    \"Hillshade\": \"HILLSHADEARC1.tif\",\n",
    "    \"NDVI\": \"NDVI1_Clip1.tif\",\n",
    "    \"Aspect\": \"ASPECTARGIS1.tif\"\n",
    "}\n",
    "\n",
    "# Read and resize all TIF files into a dictionary\n",
    "data = {}\n",
    "first_tif_shape = None\n",
    "for factor, path in tif_files.items():\n",
    "    try:\n",
    "        if first_tif_shape is None:\n",
    "            first_tif_shape = read_and_resize_tif(path, (100, 100))[0].shape\n",
    "        data[factor], _ = read_and_resize_tif(path, first_tif_shape)\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading or resizing TIF file for factor '{factor}': {e}\")\n",
    "\n",
    "# Generate a placeholder target variable (replace this with your actual labels if available)\n",
    "num_samples = min(data[key].shape[0] for key in data)\n",
    "y = np.random.randint(2, size=num_samples)  # Binary classification, replace with your actual labels\n",
    "\n",
    "# Trim data to have the same number of samples\n",
    "for key in data:\n",
    "    data[key] = data[key][:num_samples]\n",
    "\n",
    "# Stack data into a single array\n",
    "X = np.stack([data[factor] for factor in tif_files.keys()], axis=1)\n",
    "\n",
    "# Scale features to a given range using MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Fit an SVM classifier\n",
    "svm_classifier = SVC(kernel='linear')\n",
    "svm_classifier.fit(X_scaled, y)\n",
    "\n",
    "# Get feature importance scores (weights)\n",
    "weights = np.abs(svm_classifier.coef_).flatten() / np.sum(np.abs(svm_classifier.coef_))\n",
    "\n",
    "# Print weights of each factor\n",
    "for factor, weight in zip(tif_files.keys(), weights):\n",
    "    print(f\"{factor}: {weight}\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "raw",
   "id": "250286c7",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "import rasterio\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real\n",
    "\n",
    "# Define a function to read and resize TIF files\n",
    "def read_and_resize_tif(tif_path, target_shape):\n",
    "    with rasterio.open(tif_path) as src:\n",
    "        data = src.read(\n",
    "            out_shape=(src.count, *target_shape),\n",
    "            resampling=rasterio.enums.Resampling.bilinear\n",
    "        )\n",
    "        return data.flatten(), src.profile\n",
    "\n",
    "# Define paths to your TIF files\n",
    "tif_files = {\n",
    "    \"Topographic Wetness Index\": \"TWI1.tif\",\n",
    "    \"Stream Power Index\": \"SPI1.tif\",\n",
    "    \"Topographic Roughness Index\": \"TRI1.tif\",\n",
    "    \"Topographic Position Index\": \"TPI1.tif\",\n",
    "    \"Elevation\": \"demtif1.tif\",\n",
    "    \"Land use Land cover\": \"lulc1.tif\",\n",
    "    \"Distance from Road\": \"EucDist_road11.tif\",\n",
    "    \"Distance from River\": \"EucDist_Hydr11.tif\",\n",
    "    \"Slope\": \"SLOPEARCGHIS1.tif\",\n",
    "    \"Drainage Density\": \"DRAINAGE DENSITY1.tif\",\n",
    "    \"Hillshade\": \"HILLSHADEARC1.tif\",\n",
    "    \"NDVI\": \"NDVI1_Clip1.tif\",\n",
    "    \"Aspect\": \"ASPECTARGIS1.tif\"\n",
    "}\n",
    "\n",
    "# Read and resize all TIF files into a dictionary\n",
    "data = {}\n",
    "first_tif_shape = None\n",
    "for factor, path in tif_files.items():\n",
    "    try:\n",
    "        if first_tif_shape is None:\n",
    "            first_tif_shape = read_and_resize_tif(path, (100, 100))[0].shape\n",
    "        data[factor], _ = read_and_resize_tif(path, first_tif_shape)\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading or resizing TIF file for factor '{factor}': {e}\")\n",
    "\n",
    "# Generate a placeholder target variable (replace this with your actual labels if available)\n",
    "num_samples = min(data[key].shape[0] for key in data)\n",
    "y = np.random.randint(2, size=num_samples)  # Binary classification, replace with your actual labels\n",
    "\n",
    "# Trim data to have the same number of samples\n",
    "for key in data:\n",
    "    data[key] = data[key][:num_samples]\n",
    "\n",
    "# Stack data into a single array\n",
    "X = np.stack([data[factor] for factor in tif_files.keys()], axis=1)\n",
    "\n",
    "# Scale features to a given range using MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Define the parameter search space for Bayesian optimization\n",
    "paramgrid = {\n",
    "    'C': Real(1e-6, 1e+6, prior='log-uniform'),\n",
    "    'gamma': Real(1e-6, 1e+1, prior='log-uniform')\n",
    "}\n",
    "\n",
    "# Define the SVM classifier\n",
    "svm_classifier = SVC(kernel='linear')\n",
    "\n",
    "# Define the Bayesian optimization method\n",
    "cv = BayesSearchCV(estimator=svm_classifier,\n",
    "                   search_spaces=paramgrid,\n",
    "                   scoring=\"accuracy\",\n",
    "                   cv=5,\n",
    "                   n_jobs=1,\n",
    "                   n_iter=50,  # Number of parameter settings that are sampled\n",
    "                   verbose=1)\n",
    "\n",
    "# Fit the Bayesian optimization method\n",
    "cv.fit(X_scaled, y)\n",
    "\n",
    "# Get the best SVM classifier after optimization\n",
    "best_svm_classifier = cv.best_estimator_\n",
    "\n",
    "# Get feature importance scores (weights) from the optimized SVM classifier\n",
    "weights = np.abs(best_svm_classifier.coef_).flatten() / np.sum(np.abs(best_svm_classifier.coef_))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "feec084c",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "import rasterio\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Define paths to your TIF files\n",
    "tif_files = {\n",
    "    \"Topographic Wetness Index\": \"TWI1.tif\",\n",
    "    \"Stream Power Index\": \"SPI1.tif\",\n",
    "    \"Topographic Roughness Index\": \"TRI1.tif\",\n",
    "    \"Topographic Position Index\": \"TPI1.tif\",\n",
    "    \"Elevation\": \"demtif1.tif\",\n",
    "    \"Land use Land cover\": \"lulc1.tif\",\n",
    "    \"Distance from Road\": \"EucDist_road11.tif\",\n",
    "    \"Distance from River\": \"EucDist_Hydr11.tif\",\n",
    "    \"Slope\": \"SLOPEARCGHIS1.tif\",\n",
    "    \"Drainage Density\": \"DRAINAGE DENSITY1.tif\",\n",
    "    \"Hillshade\": \"HILLSHADEARC1.tif\",\n",
    "    \"NDVI\": \"NDVI1_Clip1.tif\",\n",
    "    \"Aspect\": \"ASPECTARGIS1.tif\"\n",
    "}\n",
    "\n",
    "# Read and stack all TIF files\n",
    "stacked_data = []\n",
    "for key, path in tif_files.items():\n",
    "    with rasterio.open(path) as src:\n",
    "        stacked_data.append(src.read(1))  # Read the first band\n",
    "stacked_data = np.stack(stacked_data, axis=-1)\n",
    "\n",
    "# Reshape stacked data for scaling\n",
    "num_samples, num_pixels, num_features = stacked_data.shape[0], stacked_data.shape[1] * stacked_data.shape[2], stacked_data.shape[3]\n",
    "reshaped_data = stacked_data.reshape(num_samples, num_pixels, num_features)\n",
    "\n",
    "# Scale features to a given range using MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(reshaped_data)\n",
    "\n",
    "# Fit an SVM classifier\n",
    "svm_classifier = SVC(kernel='linear')\n",
    "svm_classifier.fit(X_scaled, y)\n",
    "\n",
    "# Get feature importance scores (weights)\n",
    "weights = np.abs(svm_classifier.coef_).flatten() / np.sum(np.abs(svm_classifier.coef_))\n",
    "\n",
    "# Aggregate the weighted factors\n",
    "weighted_sum = np.zeros_like(stacked_data[:, :, 0], dtype=np.float32)\n",
    "for i, (factor, path) in enumerate(tif_files.items()):\n",
    "    with rasterio.open(path) as src:\n",
    "        weighted_sum += src.read(1) * weights[i]\n",
    "\n",
    "# Classify the susceptibility map (optional)\n",
    "# Replace this step with your classification method\n",
    "\n",
    "# Save susceptibility map as a raster\n",
    "with rasterio.open(\"flood_susceptibility_map.tif\", 'w', **src.profile) as dst:\n",
    "    dst.write(weighted_sum, 1)\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "74fda696",
   "metadata": {},
   "source": [
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Categorical, Integer\n",
    "\n",
    "# Define the parameter search space for Bayesian optimization\n",
    "paramgrid = {\n",
    "    'C': Real(1e-6, 1e+6, prior='log-uniform'),\n",
    "    'gamma': Real(1e-6, 1e+1, prior='log-uniform')\n",
    "}\n",
    "\n",
    "# Define the Bayesian optimization method\n",
    "cv = BayesSearchCV(estimator=svm_classifier,\n",
    "                   search_spaces=paramgrid,\n",
    "                   scoring=\"accuracy\",\n",
    "                   cv=5,\n",
    "                   n_jobs=1,\n",
    "                   n_iter=50,\n",
    "                   verbose=1)\n",
    "\n",
    "# Fit the Bayesian optimization method\n",
    "cv.fit(X_scaled, y)\n",
    "\n",
    "# Get the best SVM classifier after optimization\n",
    "best_svm_classifier = cv.best_estimator_\n",
    "\n",
    "# Get feature importance scores (weights) from the optimized SVM classifier\n",
    "weights = np.abs(best_svm_classifier.coef_).flatten() / np.sum(np.abs(best_svm_classifier.coef_))\n",
    "\n",
    "# Print weights of each factor\n",
    "for factor, weight in zip(tif_files.keys(), weights):\n",
    "    print(f\"{factor}: {weight}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d507d22a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-optimize\n",
      "  Downloading scikit_optimize-0.10.1-py2.py3-none-any.whl (107 kB)\n",
      "     ------------------------------------ 107.7/107.7 kB 328.3 kB/s eta 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.1.1 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\kaushik\\anaconda3\\lib\\site-packages (from scikit-optimize) (1.4.2)\n",
      "Collecting pyaml>=16.9 (from scikit-optimize)\n",
      "  Downloading pyaml-24.4.0-py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied: numpy>=1.20.3 in c:\\users\\kaushik\\anaconda3\\lib\\site-packages (from scikit-optimize) (1.23.5)\n",
      "Requirement already satisfied: scipy>=1.1.0 in c:\\users\\kaushik\\anaconda3\\lib\\site-packages (from scikit-optimize) (1.10.1)\n",
      "Requirement already satisfied: scikit-learn>=1.0.0 in c:\\users\\kaushik\\anaconda3\\lib\\site-packages (from scikit-optimize) (1.3.2)\n",
      "Requirement already satisfied: packaging>=21.3 in c:\\users\\kaushik\\anaconda3\\lib\\site-packages (from scikit-optimize) (24.0)\n",
      "Requirement already satisfied: PyYAML in c:\\users\\kaushik\\anaconda3\\lib\\site-packages (from pyaml>=16.9->scikit-optimize) (5.4.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\kaushik\\anaconda3\\lib\\site-packages (from scikit-learn>=1.0.0->scikit-optimize) (2.1.0)\n",
      "Installing collected packages: pyaml, scikit-optimize\n",
      "Successfully installed pyaml-24.4.0 scikit-optimize-0.10.1\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-optimize\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d3c88ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
